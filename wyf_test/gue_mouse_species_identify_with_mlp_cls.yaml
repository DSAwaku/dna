trainer:
  accelerator: auto
  devices: auto
  strategy: auto
  max_epochs: 20
  num_nodes: 1  # Number of compute nodes
  gradient_clip_val: 1
  default_root_dir: logs
  logger: false
  callbacks:
  - class_path: lightning.pytorch.callbacks.ModelCheckpoint # Save checkpoint at the end of each epoch, and save the best val_mcc checkpoint
    init_args:
      dirpath: null
      filename: epoch_{epoch}-val_mcc:{val_mcc:.3f}
      monitor: val_mcc
      mode: max
      every_n_epochs: 1
  - class_path: lightning.pytorch.callbacks.early_stopping.EarlyStopping
    dict_kwargs:
      monitor: val_mcc
      mode: max
      patience: 10
model:
  class_path: modelgenerator.tasks.SequenceClassification
  init_args:
    backbone:
      class_path: modelgenerator.backbones.aido_dna_300m
      init_args:
        use_peft: true
    n_classes: 2
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 0.0005
        weight_decay: 0.1
    adapter:
      class_path: modelgenerator.adapters.MLPPoolAdapter
      init_args:
        pooling: "cls_pooling"
        hidden_sizes: [512, 256, 128]
        dropout: 0.0
        activation_layer: torch.nn.Tanh
        bias: true
        dropout_in_middle: true
    lr_scheduler:
      class_path: modelgenerator.lr_schedulers.CosineWithWarmup
      init_args:
        warmup_ratio: 0.1
data:
  class_path: modelgenerator.data.GUEClassification
  init_args:
    config_name: mouse_1
    train_split_name: train
    test_split_name: test
    batch_size: 64
